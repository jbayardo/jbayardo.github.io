<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Julian through the Lens</title>
    <link>https://julian.bayardo.info/</link>
    <description>Recent content on Julian through the Lens</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 20 Aug 2018 19:23:28 -0300</lastBuildDate>
    
	<atom:link href="https://julian.bayardo.info/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>NCH is roto-translation invariant</title>
      <link>https://julian.bayardo.info/posts/nch-roto-translation-invariant/</link>
      <pubDate>Mon, 20 Aug 2018 19:23:28 -0300</pubDate>
      
      <guid>https://julian.bayardo.info/posts/nch-roto-translation-invariant/</guid>
      <description>Introduction I have recently started my thesis on 3D surface reconstruction. One way to do so is to define a surface as the zero level set of a function $f : \mathbb{R}^3 \to \mathbb{R}$, and then find some way to build this function out of a set of points $\mathcal{P} \subset \mathbb{R}^3$. NCH is a method that allows you to define such a function starting from a point cloud along with their normals, which tell you which way is the inside of the surface.</description>
    </item>
    
    <item>
      <title>Processing Trees with Recursion Schemes</title>
      <link>https://julian.bayardo.info/posts/processing-trees-recursion-schemes/</link>
      <pubDate>Sat, 02 Jun 2018 20:51:15 -0300</pubDate>
      
      <guid>https://julian.bayardo.info/posts/processing-trees-recursion-schemes/</guid>
      <description>A long time ago, I was in touch with a production system whose purpose was to run a piece of data through a decision tree. At every step, the output could be Good, Bad, Move Left, or Move Right; there were no leaves, since at the end you were supposed to always have returned either Good or Bad (this means it would be an error for you to get there).</description>
    </item>
    
    <item>
      <title>Understanding Modulo Bias</title>
      <link>https://julian.bayardo.info/posts/understanding-modulo-bias/</link>
      <pubDate>Wed, 02 May 2018 20:26:06 -0300</pubDate>
      
      <guid>https://julian.bayardo.info/posts/understanding-modulo-bias/</guid>
      <description>It is often said that this code:
unsigned int randomNumber = rand() % k;  is a bad idea, at least if you are expecting a uniform distribution. I&amp;rsquo;m going to try and explore this topic in a more formal fashion than I have seen so far.
The reason why it is bad is pretty elementary and easy to understand: imagine you have a random generator that outputs values between \(0\) and \(9\) (i.</description>
    </item>
    
    <item>
      <title>Yet Another Proof of Brooke&#39;s Theorem</title>
      <link>https://julian.bayardo.info/posts/yet-another-proof-of-brookes-theorem/</link>
      <pubDate>Sat, 30 Apr 2016 20:28:23 -0300</pubDate>
      
      <guid>https://julian.bayardo.info/posts/yet-another-proof-of-brookes-theorem/</guid>
      <description>A classical result from Graph theory is that given \(G\) an undirected graph:
\chi(G) \leq \Delta(G) + 1  Where \(\chi(G)\) is the minimum number of colors required to paint the nodes of \(G\) with the usual restriction that no node has the same color as any of its neighbors, and \(\Delta(G) = max_{v \in V(G)}(dg(v))\), that is, the maximum degree. This result is known as Brooke&amp;rsquo;s Theorem.
The usual way to prove this result is to use the Greedy coloring algorithm: go through every node, and pick the lowest color not yet used by any of its neighbors.</description>
    </item>
    
    <item>
      <title>Characterizing the trace of a matrix</title>
      <link>https://julian.bayardo.info/posts/matrix-trace-characterization/</link>
      <pubDate>Fri, 24 Jul 2015 20:09:13 -0300</pubDate>
      
      <guid>https://julian.bayardo.info/posts/matrix-trace-characterization/</guid>
      <description>I have been studying for my finals lately, and so I decided to put together a proof of a nice exercise I found in some book. The trace function, given by \(tr : \mathbb{K}^{n \times n} \to \mathbb{K}\), is defined as
tr(A) = \sum_{i=1}^n A_{ii}  First of all, the proof of additivity
\begin{equation} \begin{split} tr(A + B) &amp;= \sum_{i=1}^n (A+B)_{ii} \\ &amp;= \sum_{i=1}^n (A)_{ii} + (B)_{ii} \\ &amp;= \sum_{i=1}^n (A)_{ii} + \sum_{i=1}^n (B)_{ii} \\ &amp;= tr(A) + tr(B) \end{split} \end{equation}  Afterwards, the proof of homogeneity</description>
    </item>
    
  </channel>
</rss>