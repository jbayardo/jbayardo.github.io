<!doctype html><html xmlns=http://www.w3.org/1999/xhtml lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Characterizing the trace of a matrix | Julian through the Lens</title>
<meta property='og:title' content='Characterizing the trace of a matrix - Julian through the Lens'><meta property='og:description' content='I have been studying for my finals lately, and so I decided to put together a proof of a nice exercise I found in some book. The trace function, given by \(tr : \mathbb{K}^{n \times n} \to \mathbb{K}\), is defined as
First of all, the proof of additivity
Afterwards, the proof of homogeneity
Hence, \(tr\) is a linear transform from the vector space \(\mathbb{K}^{n \times n}\) into \(\mathbb{K}\). The cool thing about the trace is that it has many more interesting properties which are not difficult to prove.'><meta property='og:url' content='https://julian.bayardo.info/post/matrix-trace-characterization/'><meta property='og:site_name' content='Julian through the Lens'><meta property='og:type' content='article'><meta property='og:image' content='https://www.gravatar.com/avatar/fdbc036a46f3c0903c7e39459db599c0?s=256'><meta property='article:section' content='Post'><meta property='article:tag' content='linear-algebra'><meta property='article:published_time' content='2015-07-24T20:09:13-03:00'><meta property='article:modified_time' content='2015-07-24T20:09:13-03:00'><meta name=twitter:card content='summary'><meta name=twitter:site content='@BayardoJulian'><meta name=twitter:creator content='@BayardoJulian'><link rel=alternate type=application/rss+xml title="Julian through the Lens" href=/post/index.xml><link rel=stylesheet href=/css/style.min.572ee845ad8da3c5d2a0a9e157da4b896325fafa6ff5b9b18ae122044000e00e.css><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=canonical href=https://julian.bayardo.info/post/matrix-trace-characterization/><meta name=msapplication-TileColor content="#da532c"><meta name=theme-color content="#ffffff"></head><body><header class=section><div class=container><nav id=nav-main class=nav><div id=nav-name class=nav-left><a id=nav-anchor class=nav-item href=https://julian.bayardo.info/><h1 id=nav-heading class="title is-4">Julian through the Lens</h1></a></div><div class=nav-right><nav id=nav-items class="nav-item level is-mobile"><a class=level-item aria-label=github href=https://github.com/jbayardo target=_blank rel=noopener><span class=icon><i><svg viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg>
</i></span></a><a class=level-item aria-label=email href=mailto:julian@bayardo.info target=_blank rel=noopener><span class=icon><i><svg viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg>
</i></span></a><a class=level-item aria-label=linkedin href=https://linkedin.com/in/jbayardo target=_blank rel=noopener><span class=icon><i><svg viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path stroke-width="1.8" d="m5.839218 4.101561c0 1.211972-.974141 2.194011-2.176459 2.194011S1.4863 5.313533 1.4863 4.101561c0-1.211094.974141-2.194011 2.176459-2.194011s2.176459.982917 2.176459 2.194011zm.017552 3.94922H1.468748v14.04167H5.85677V8.050781zm7.005038.0H8.501869v14.04167h4.360816v-7.370999c0-4.098413 5.291077-4.433657 5.291077.0v7.370999h4.377491v-8.89101c0-6.915523-7.829986-6.66365-9.669445-3.259423V8.050781z"/></svg></i></span></a></nav></div></nav><nav class=nav><div class=nav-left><a class=nav-item href=/search><h2 class="title is-5">Search</h2></a><a class=nav-item href=/series><h2 class="title is-5">Series</h2></a><a class=nav-item href=/tags><h2 class="title is-5">Tags</h2></a></div><div class=nav-right><a class=nav-item href=/about><h2 class="title is-5">About me</h2></a><a class=nav-item href=/disclaimer><h2 class="title is-5">Disclaimer</h2></a></div></nav></div><script src=/js/navicon-shift.min.c7620c1a856fc9aead68a6e5fa7d6a739ac88b0ef5eb6834fb6dacf7dc82adc3.js integrity="sha256-x2IMGoVvya6taKbl+n1qc5rIiw7162g0+22s99yCrcM=" crossorigin=anonymous async defer></script></header><section class="section article-section"><article class=article data-pagefind-body><div class=article-container><div class=container><div class="subtitle tags is-6 is-pulled-right"><a class="tag is-6 is-link" href=/tags/linear-algebra data-pagefind-filter=tag><svg viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2H12l8.59 8.59a2 2 0 010 2.82z"/><line x1="7" y1="7" x2="7" y2="7"/></svg>
linear-algebra</a></div><h2 class="subtitle is-6" data-pagefind-meta=date>July 24, 2015</h2><h1 class=title data-pagefind-meta=title>Characterizing the trace of a matrix</h1><div class="content article"><p>I have been studying for my finals lately, and so I decided to put together a proof of a nice exercise I found in some book. The trace function, given by \(tr : \mathbb{K}^{n \times n} \to \mathbb{K}\), is defined as</p><script type="math/tex;mode=display">tr(A) = \sum_{i=1}^n A_{ii}
</script><p>First of all, the proof of additivity</p><script type="math/tex;mode=display">\begin{equation}
\begin{split}
tr(A + B) &= \sum_{i=1}^n (A+B)_{ii} \\
&= \sum_{i=1}^n (A)_{ii} + (B)_{ii} \\
&= \sum_{i=1}^n (A)_{ii} + \sum_{i=1}^n (B)_{ii} \\
&= tr(A) + tr(B)
\end{split}
\end{equation}
</script><p>Afterwards, the proof of homogeneity</p><script type="math/tex;mode=display">\begin{equation}
\begin{split}
tr(\lambda A) &= \sum_{i=1}^n (\lambda A)_{ii}\\
&= \sum_{i=1}^n \lambda A_{ii}\\
&= \lambda \sum_{i=1}^n A_{ii}\\
&= \lambda tr(A)
\end{split}
\end{equation}
</script><p>Hence, \(tr\) is a linear transform from the vector space \(\mathbb{K}^{n \times n}\) into \(\mathbb{K}\). The cool thing about the trace is that it has many more interesting properties which are not difficult to prove. First of all, that it is invariant under transposition</p><script type="math/tex;mode=display">\begin{equation}
\begin{split}
tr(A^T) &= \sum_{i=1}^n (A^T)_{ii}\\
&= \sum_{i=1}^n A_{ii}\\
&= tr(A)
\end{split}
\end{equation}
</script><p>And that it doesn&rsquo;t change when a product commutes</p><script type="math/tex;mode=display">\begin{equation}
\begin{split}
tr(AB) &= \sum_{i=1}^n (AB)_{ii}\\
&= \sum_{i=1}^n \sum_{k=1}^n A_{ik} B_{ki}\\
&= \sum_{k=1}^n \sum_{i=1}^n B_{ki} A_{ik}\\
&= \sum_{k=1}^n (BA)_{kk}\\
&= tr(BA)
\end{split}
\end{equation}
</script><p>Therefore, we get a pretty non-intuitive property of the trace, we have that</p><script type="math/tex;mode=display">tr(ABC) = tr(BCA) = tr(CAB)
</script><p>Which comes from applying the previous property to different parenthesizations of the matrix product (notice that this is doable for any number of matrices). Going further, suppose that \(P \in \mathbb{K}^{n \times n}\) is an invertible matrix, then</p><script type="math/tex;mode=display">tr(PAP^{-1}) = tr(AP^{-1}P) = tr(A)
</script><p>Meaning that if two matrices \(A\) and \(B\) are similar, their traces are the same!. Additionally, writing \(A\) in any given basis will not change its trace. Last of all, the reason I decided to write this post:</p><p>Suppose that we have a linear functional \(f : \mathbb{K}^{n \times n} \to \mathbb{K}\) such that \(\forall A, B : f(AB) = f(BA)\), then \(\exists \lambda \in \mathbb{K} / f(A) = \lambda tr(A)\). That is, linearity and the product property completely determine the trace function, up to a constant factor. The proof is fairly easy. Let</p><script type="math/tex;mode=display">\beta = {E^{ij}}_{1 \leq i, j \leq n}
</script><p>be the canonical ordered basis for \(\mathbb{K}^{n \times n}\). Notice that:</p><script type="math/tex;mode=display">\begin{equation}
\begin{split}
E^{ij} E^{kl} &= \sum_{m=1}^n E^{ij}_{i'm} E^{kl}_{mj'}\\
&= \sum_{m=1}^n \delta_{ii'} \delta_{jm} \delta_{km} \delta_{lj'}\\
&= \delta_{ii'} \delta_{lj'} \delta_{jk}
\end{split}
\end{equation}
</script><p>Since \(f\) is a linear functional, we can write it as \(f(A) = \sum_{i, j = 1}^n \alpha_{ij} \phi_{ij}(A)\), where \(\phi_{ij}\) are the corresponding functions from the dual basis, meaning that \(\phi_{ij}(E^{i&rsquo;j&rsquo;}) = \delta_{ii&rsquo;} \delta_{jj&rsquo;}\). Thus, we get that</p><script type="math/tex;mode=display">f(E^{ij} E^{lm}) = \alpha_{im} \delta_{jl}
</script><p>And</p><script type="math/tex;mode=display">f(E^{lm} E^{ij}) = \alpha_{mi} \delta_{lj}
</script><p>The additional condition that \(f(AB) = f(BA)\) means that \(\alpha_{im} \delta_{jl} = \alpha_{mi} \delta_{lj} \forall i, j, m, l \in {1, &mldr;, n}\). In particular, if we take \(i = m, j = l\), this turns into \(\alpha_{ii} \delta_{jj} = \alpha_{ii} \delta_{jj}\), which implies that \(\delta_{ii} = \delta_{jj} \forall i, j \in {1, &mldr;, n}\), we can call this value \(\lambda\). Finally, taking \(l \neq j, m = i\), we get that \(\alpha_{lj} = 0 \forall l, j \in {1, &mldr;, n}, l \neq j\). This completely determines every single one of the \(\alpha\)s. Hence:</p><script type="math/tex;mode=display">f(A) = \lambda \sum_{i = 1}^n \phi_{ii}(A) = \lambda \sum_{i = 1}^n A_{ii} = \lambda tr(A)
</script><p>By this point, we have pretty much characterized the trace function, in the sense that we know that any function that is a linear transform and does not change when the matrix product order changes, then it is a scalar multiple of the trace. There is only one last important property to uniquely determine the trace. Given \(f\) with the previous properties, \(f(I) = n \iff f = tr\):</p><script type="math/tex;mode=display">f(I) = \lambda tr(I) = \lambda n = n
</script><p>Which happens if and only if \(\lambda = 1\).I have been studying for my finals lately, and so I decided to put together a proof of a nice exercise I found in some book. The trace function, given by \(tr : \mathbb{K}^{n \times n} \to \mathbb{K}\), is defined as</p><script type="math/tex;mode=display">tr(A) = \sum_{i=1}^n A_{ii}
</script><p>First of all, the proof of additivity</p><script type="math/tex;mode=display">\begin{equation}
\begin{split}
tr(A + B) &= \sum_{i=1}^n (A+B)_{ii} \\
&= \sum_{i=1}^n (A)_{ii} + (B)_{ii} \\
&= \sum_{i=1}^n (A)_{ii} + \sum_{i=1}^n (B)_{ii} \\
&= tr(A) + tr(B)
\end{split}
\end{equation}
</script><p>Afterwards, the proof of homogeneity</p><script type="math/tex;mode=display">\begin{equation}
\begin{split}
tr(\lambda A) &= \sum_{i=1}^n (\lambda A)_{ii}\\
&= \sum_{i=1}^n \lambda A_{ii}\\
&= \lambda \sum_{i=1}^n A_{ii}\\
&= \lambda tr(A)
\end{split}
\end{equation}
</script><p>Hence, \(tr\) is a linear transform from the vector space \(\mathbb{K}^{n \times n}\) into \(\mathbb{K}\). The cool thing about the trace is that it has many more interesting properties which are not difficult to prove. First of all, that it is invariant under transposition</p><script type="math/tex;mode=display">\begin{equation}
\begin{split}
tr(A^T) &= \sum_{i=1}^n (A^T)_{ii}\\
&= \sum_{i=1}^n A_{ii}\\
&= tr(A)
\end{split}
\end{equation}
</script><p>And that it doesn&rsquo;t change when a product commutes</p><script type="math/tex;mode=display">\begin{equation}
\begin{split}
tr(AB) &= \sum_{i=1}^n (AB)_{ii}\\
&= \sum_{i=1}^n \sum_{k=1}^n A_{ik} B_{ki}\\
&= \sum_{k=1}^n \sum_{i=1}^n B_{ki} A_{ik}\\
&= \sum_{k=1}^n (BA)_{kk}\\
&= tr(BA)
\end{split}
\end{equation}
</script><p>Therefore, we get a pretty non-intuitive property of the trace, we have that</p><script type="math/tex;mode=display">tr(ABC) = tr(BCA) = tr(CAB)
</script><p>Which comes from applying the previous property to different parenthesizations of the matrix product (notice that this is doable for any number of matrices). Going further, suppose that \(P \in \mathbb{K}^{n \times n}\) is an invertible matrix, then</p><script type="math/tex;mode=display">tr(PAP^{-1}) = tr(AP^{-1}P) = tr(A)
</script><p>Meaning that if two matrices \(A\) and \(B\) are similar, their traces are the same!. Additionally, writing \(A\) in any given basis will not change its trace. Last of all, the reason I decided to write this post:</p><p>Suppose that we have a linear functional \(f : \mathbb{K}^{n \times n} \to \mathbb{K}\) such that \(\forall A, B : f(AB) = f(BA)\), then \(\exists \lambda \in \mathbb{K} / f(A) = \lambda tr(A)\). That is, linearity and the product property completely determine the trace function, up to a constant factor. The proof is fairly easy. Let</p><script type="math/tex;mode=display">\beta = {E^{ij}}_{1 \leq i, j \leq n}
</script><p>be the canonical ordered basis for \(\mathbb{K}^{n \times n}\). Notice that:</p><script type="math/tex;mode=display">\begin{equation}
\begin{split}
E^{ij} E^{kl} &= \sum_{m=1}^n E^{ij}_{i'm} E^{kl}_{mj'}\\
&= \sum_{m=1}^n \delta_{ii'} \delta_{jm} \delta_{km} \delta_{lj'}\\
&= \delta_{ii'} \delta_{lj'} \delta_{jk}
\end{split}
\end{equation}
</script><p>Since \(f\) is a linear functional, we can write it as \(f(A) = \sum_{i, j = 1}^n \alpha_{ij} \phi_{ij}(A)\), where \(\phi_{ij}\) are the corresponding functions from the dual basis, meaning that \(\phi_{ij}(E^{i&rsquo;j&rsquo;}) = \delta_{ii&rsquo;} \delta_{jj&rsquo;}\). Thus, we get that</p><script type="math/tex;mode=display">f(E^{ij} E^{lm}) = \alpha_{im} \delta_{jl}
</script><p>And</p><script type="math/tex;mode=display">f(E^{lm} E^{ij}) = \alpha_{mi} \delta_{lj}
</script><p>The additional condition that \(f(AB) = f(BA)\) means that \(\alpha_{im} \delta_{jl} = \alpha_{mi} \delta_{lj} \forall i, j, m, l \in {1, &mldr;, n}\). In particular, if we take \(i = m, j = l\), this turns into \(\alpha_{ii} \delta_{jj} = \alpha_{ii} \delta_{jj}\), which implies that \(\delta_{ii} = \delta_{jj} \forall i, j \in {1, &mldr;, n}\), we can call this value \(\lambda\). Finally, taking \(l \neq j, m = i\), we get that \(\alpha_{lj} = 0 \forall l, j \in {1, &mldr;, n}, l \neq j\). This completely determines every single one of the \(\alpha\)s. Hence:</p><script type="math/tex;mode=display">f(A) = \lambda \sum_{i = 1}^n \phi_{ii}(A) = \lambda \sum_{i = 1}^n A_{ii} = \lambda tr(A)
</script><p>By this point, we have pretty much characterized the trace function, in the sense that we know that any function that is a linear transform and does not change when the matrix product order changes, then it is a scalar multiple of the trace. There is only one last important property to uniquely determine the trace. Given \(f\) with the previous properties, \(f(I) = n \iff f = tr\):</p><script type="math/tex;mode=display">f(I) = \lambda tr(I) = \lambda n = n
</script><p>Which happens if and only if \(\lambda = 1\).</p></div><div class=content data-pagefind-ignore=all></div><button id=load-comments-button class="button is-primary is-active is-large is-fullwidth" style=display:none>Load Comments</button>
<script src=/js/comments.min.39e33edd67905b2b36477104baf1ec48ae8d66edab407617757a4adf0f6b75a0.js integrity="sha256-OeM+3WeQWys2R3EEuvHsSK6NZu2rQHYXdXpK3w9rdaA=" crossorigin=anonymous async defer></script></div></div></article></section><div class=top-button><a href=https://julian.bayardo.info/post/matrix-trace-characterization/#><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-up"><line x1="12" y1="19" x2="12" y2="5"/><polyline points="5 12 12 5 19 12"/></svg></a></div><footer class=section style=padding-top:0><div class=container><hr><p style=float:left>&copy; Julian Bayardo Spadafora 2015-2024 | <a href=/privacy-policy/>Privacy Policy</a> | <a href=/terms-of-service/>Terms of Service</a></p><div style=float:right><a href=https://julian.bayardo.info/post/matrix-trace-characterization/#>Back to Top</a></div></div></footer><script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["[","]"]],processEscapes:!0,processEnvironments:!0,autoload:{color:[],colorV2:["color"]},packages:{"[+]":["noerrors"]}},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"],ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process",renderActions:{find_script_mathtex:[10,function(e){for(const t of document.querySelectorAll('script[type^="math/tex"]')){const o=!!t.type.match(/; *mode=display/),n=new e.options.MathItem(t.textContent,e.inputJax[0],o),s=document.createTextNode("");t.parentNode.replaceChild(s,t),n.start={node:s,delim:"",n:0},n.end={node:s,delim:"",n:0},e.math.push(n)}},""]}},loader:{load:["input/asciimath","[tex]/noerrors"]}}</script><script type=text/javascript id=MathJax-script async defer src=/js/vendor/mathjax/tex-mml-chtml.js></script></body></html>